## Make VLMs Memorize Normality: Memory-Enhanced Vision-Language Model for Video Anomaly Detection 👋
![MEMVLM](https://github.com/user-attachments/assets/830f86d5-5622-4547-8c54-543fa40b7dd4)

# MEMVLM

This is the **official code repository** for **Make VLMs Memorize Normality: Memory-Enhanced Vision-Language Model for Video Anomaly Detection**.

## 🔍 Introduction

MEMVLM is a vision-language model designed for multimodal anomaly detection.

This repository currently provides evaluation code for measuring model performance.

## 🚀 Quick Start

Make sure all dependencies in eval.py are installed, then run the following command to evaluate the model:

```bash
python eval.py


## 📌 Full Code

The full training and development code will be released after the corresponding paper is accepted. Stay tuned!
